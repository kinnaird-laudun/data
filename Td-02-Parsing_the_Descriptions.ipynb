{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Parsing the Descriptions\n",
    "\n",
    "In this notebook, we are going to parse the main pages downloaded and saved in the `descriptions` directory.\n",
    "\n",
    "Like the transcripts, we are going to use the `public_URL` as the key to merge the CSVs: we are probably going to use the `pandas` dataframe merge functionality to do this, but there may very well be something in the `csv` library. \n",
    "\n",
    "    <link rel=\"canonical\" href=\"https://www.ted.com/talks/al_gore_on_averting_climate_crisis\" />\n",
    "I can re-use the BeautifulSoup code I wrote for the transcripts to locate the `link` tag with the `rel=\"canonical\"` attribute, but I won't need to delete trailing `/transcript`.\n",
    "\n",
    "The first thing I'm going to do is to check the extant code against the new files with a small test directory of 3 files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# =-=-=-=-=-=-=-=-=-=-=\n",
    "# Import libraries\n",
    "# =-=-=-=-=-=-=-=-=-=-= \n",
    "import pandas, re, csv, os, json\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# =-=-=-=-=-=-=-=-=-=-=\n",
    "# Define functions\n",
    "# =-=-=-=-=-=-=-=-=-=-= \n",
    "\n",
    "def get_description(thesoup):\n",
    "    # This is the most normal part of this function: it follows BS4 methodology strictly.\n",
    "    # UPDATE: Commenting out ['href'] to see if that fixes the TypeError\n",
    "    public_URL = thesoup.find(\"link\", {'rel': 'canonical'}) #['href']\n",
    "    # The data we want is wrapped inside a script tag and is not formatted in a way\n",
    "    # that BS4 understands. This is a list comprehension that will then allow us to \n",
    "    # create a JSON object from which we can readily call the data we want\n",
    "    my_list = [i.string.lstrip('q(\"talkPage.init\", {\\n\\t\"el\": \"[data-talk-page]\",\\n\\t \"__INITIAL_DATA__\":')\n",
    "           .rstrip('})')\n",
    "           for i in thesoup.select('script') \n",
    "           if i.string and i.string.startswith('q')]\n",
    "    # One line of kinda ugly code to turn the list into a json object\n",
    "    the_json = json.loads('{\"' + \"\".join(my_list))\n",
    "\n",
    "    talk_id = the_json['current_talk']\n",
    "    description = the_json['description']\n",
    "    views = the_json['viewed_count']\n",
    "    event = the_json['event']\n",
    "    return public_URL, talk_id, description, views, event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def to_csv_test(the_path, out):\n",
    "    # open file to write to.\n",
    "    with open(out, \"w\") as out:\n",
    "        # create csv.writer. \n",
    "        wr = csv.writer(out)\n",
    "        # write our headers.\n",
    "        wr.writerow([\"public_URL\", \"talk_id\", \"description\", \"views\", \"event\"])\n",
    "        # get all our html files.\n",
    "        for the_file in os.listdir(the_path):\n",
    "            print(the_file)\n",
    "            with open(os.path.join(the_path, the_file)) as f:\n",
    "                # parse the file and write the data to a row.\n",
    "                # Try/Else needs to go here?\n",
    "                try:\n",
    "                    wr.writerow(get_description(BeautifulSoup(f, \"html5lib\")))\n",
    "                except ValueError:\n",
    "                    print('Error with ' + the_file)        \n",
    "                finally:\n",
    "                    wr.writerow(get_description(BeautifulSoup(f, \"html5lib\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def to_csv(the_path, out):\n",
    "    # open file to write to\n",
    "    with open(out, \"w\") as out:\n",
    "        # create csv.writer\n",
    "        wr = csv.writer(out)\n",
    "        # write our headers.\n",
    "        wr.writerow([\"public_URL\", \"talk_id\", \"description\", \"views\", \"event\"])\n",
    "        # get all our html files\n",
    "        for the_file in os.listdir(the_path):\n",
    "            with open(os.path.join(the_path, the_file)) as f:\n",
    "                # parse the file and write the data to a row.\n",
    "                wr.writerow(get_description(BeautifulSoup(f, \"html5lib\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# =-=-=-=-=-=-=-=-=-=-=\n",
    "# Write the CSV\n",
    "# =-=-=-=-=-=-=-=-=-=-= \n",
    "\n",
    "to_csv(\"./test_descriptions\",\"test_descriptions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# =-=-=-=-=-=-=-=-=-=-=\n",
    "# LOAD the CSV into a Pandas dataframe to check our work\n",
    "# =-=-=-=-=-=-=-=-=-=-= \n",
    "\n",
    "# Let python create the column names list:\n",
    "with open('./test_descriptions.csv') as f:\n",
    "    colnames = f.readline().strip().split(\",\")\n",
    "\n",
    "# Now will import the csv as a dataframe with the column names specified\n",
    "TEDtalks = pandas.read_csv('./test_descriptions.csv', names=colnames)\n",
    "\n",
    "# Check for success:\n",
    "TEDtalks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unterminated string starting at: line 1 column 2 (char 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-42b979cb6b6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mto_csv_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./descriptions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"descriptions.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-d0252fb8f018>\u001b[0m in \u001b[0;36mto_csv_test\u001b[0;34m(the_path, out)\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Error with '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mthe_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                     \u001b[0mwr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"html5lib\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-e433924df7a0>\u001b[0m in \u001b[0;36mget_description\u001b[0;34m(thesoup)\u001b[0m\n\u001b[1;32m     15\u001b[0m            if i.string and i.string.startswith('q')]\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# One line of kinda ugly code to turn the list into a json object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mthe_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{\"'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mtalk_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthe_json\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'current_talk'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \"\"\"\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    357\u001b[0m         \"\"\"\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrmsg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unterminated string starting at: line 1 column 2 (char 1)"
     ]
    }
   ],
   "source": [
    "to_csv_test(\"./descriptions\",\"descriptions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Caught an error\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-7-0e20793f003b>\", line 6, in <module>\n",
      "    to_csv(\"./descriptions\",\"descriptions.csv\")\n",
      "  File \"<ipython-input-3-f7b42c7689c8>\", line 12, in to_csv\n",
      "    wr.writerow(get_description(BeautifulSoup(f, \"html5lib\")))\n",
      "  File \"<ipython-input-2-e433924df7a0>\", line 17, in get_description\n",
      "    the_json = json.loads('{\"' + \"\".join(my_list))\n",
      "  File \"/opt/local/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/json/__init__.py\", line 318, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/local/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/json/decoder.py\", line 343, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/local/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/json/decoder.py\", line 359, in raw_decode\n",
      "    obj, end = self.scan_once(s, idx)\n",
      "ValueError: Expecting ':' delimiter: line 1 column 21 (char 20)\n"
     ]
    }
   ],
   "source": [
    "# Early work to create a try/except workaround for the errors we are getting.\n",
    "\n",
    "import logging\n",
    "\n",
    "try:\n",
    "    to_csv(\"./descriptions\",\"descriptions.csv\")\n",
    "except Exception as ex:\n",
    "    logging.exception('Caught an error')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
